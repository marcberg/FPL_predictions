{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Marcus Bergdahl\\\\data_science_projects\\\\FPL_predictions'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data.api.game_functions import get_game_list\n",
    "from src.components.data.api.player_functions import get_player_details, get_player_info, get_player_hist, get_player_id, get_player_name\n",
    "from src.components.data.api.round_functions import get_round_info\n",
    "\n",
    "from src.components.data.fetch_data import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-06-26. New season schedule been updated and previous season history has not been saved yet. change code in fetch_data when its back.\n",
    "# 2023-07-11. Skip previous season if there csv-file is not created yet.\n",
    "\n",
    "fetch_data(get_game_list)\n",
    "fetch_data(get_player_details)\n",
    "fetch_data(get_player_hist, season_specific=False)\n",
    "fetch_data(get_player_info)\n",
    "fetch_data(get_player_id, season_specific=False)\n",
    "fetch_data(get_player_name, season_specific=False)\n",
    "fetch_data(get_round_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data.transform_data import create_data\n",
    "\n",
    "create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.ml.data_ingest_transform_train import DataIngest, DataTranformTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingest = DataIngest()  \n",
    "data_ingest.create_train_and_test()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb \n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"Logistic Regression\":{\n",
    "        'model__C': [0.001, 0.01, 0.1, 1, 10], \n",
    "        'model__penalty': ['l1', 'l2'],  \n",
    "        'model__max_iter': [100, 1000, 10000],  \n",
    "        'model__solver': ['liblinear', 'saga']  \n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'model__criterion': ['entropy', 'gini'], \n",
    "        'model__max_depth': [None, 2, 3, 4, 5, 6], \n",
    "        'model__min_samples_leaf': [1, 2, 5, 10, 20],  \n",
    "        'model__min_samples_split': [2, 5, 10],  \n",
    "    },\n",
    "    \"Random Forest\":{\n",
    "        'model__bootstrap': [True],\n",
    "        'model__max_features': ['sqrt', 'log2', None],\n",
    "        #'model__max_features': [10, 20, 50],\n",
    "        'model__max_depth': [2, 3, 4, 6],\n",
    "        'model__min_samples_leaf': [1, 2, 4, 5, 10, 20, 50],\n",
    "        'model__n_estimators': [10, 50, 100, 500, 1000],\n",
    "    },\n",
    "    \"Gradient Boosting\":{\n",
    "        \"model__loss\":[\"log_loss\", \"exponential\"],\n",
    "        'model__learning_rate': [0.001, 0.005, 0.01, 0.015, 0.03, 0.06],\n",
    "        'model__min_samples_leaf': [1, 2, 5, 10, 20, 50],\n",
    "        'model__max_depth': [2, 3, 4, 6],\n",
    "        'model__n_estimators': [10, 50, 100],\n",
    "    },\n",
    "    \"XGBoost\":{\n",
    "        'model__max_depth': [2, 3, 4, 6],\n",
    "        'model__learning_rate': [0.001, 0.005, 0.01, 0.015, 0.03, 0.06],\n",
    "        'model__n_estimators': [10, 50, 100, 500],\n",
    "        'model__min_child_weight': [3, 5, 10, 50],\n",
    "        'model__gamma': [0, 0.1, 1, 2],\n",
    "        'model__reg_lambda': [0, 0.1, 1, 10]\n",
    "    },   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb \n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"Logistic Regression\":{\n",
    "        'model__C': [0.001, 0.01, 0.1, 1, 10], \n",
    "        'model__penalty': ['l1', 'l2'],  \n",
    "        'model__max_iter': [100, 1000, 10000],  \n",
    "        'model__solver': ['liblinear', 'saga']  \n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'model__criterion': ['entropy', 'gini'], \n",
    "        'model__max_depth': [None, 2, 3, 4, 5, 6], \n",
    "        'model__min_samples_leaf': [1, 2, 5, 10, 20],  \n",
    "        'model__min_samples_split': [2, 5, 10],  \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_1\n",
      "- Importing train, test and val\n",
      "- Calculating significant features\n",
      "- Hyperparameter-tuning and training best model for each algo: \n",
      "\n",
      "Logistic Regression\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "              Algorithm              Metric  Metric value\n",
      "0   Logistic Regression       AUC-ROC Train      0.728215\n",
      "1   Logistic Regression         AUC-ROC Val      0.730375\n",
      "2   Logistic Regression       AUC-PRC Train      0.688654\n",
      "3   Logistic Regression         AUC-PRC Val      0.650919\n",
      "4   Logistic Regression      Accuracy Train      0.670788\n",
      "5   Logistic Regression        Accuracy Val      0.685185\n",
      "6   Logistic Regression  Precision Train: 0      0.677083\n",
      "7   Logistic Regression    Precision Val: 0      0.701987\n",
      "8   Logistic Regression  Precision Train: 1      0.658140\n",
      "9   Logistic Regression    Precision Val: 1      0.646154\n",
      "10  Logistic Regression     Recall Train: 0      0.799180\n",
      "11  Logistic Regression       Recall Val: 0      0.821705\n",
      "12  Logistic Regression     Recall Train: 1      0.503559\n",
      "13  Logistic Regression       Recall Val: 1      0.482759\n",
      "14  Logistic Regression   F1-score Train: 0      0.733083\n",
      "15  Logistic Regression     F1-score Val: 0      0.757143\n",
      "16  Logistic Regression   F1-score Train: 1      0.570565\n",
      "17  Logistic Regression     F1-score Val: 1      0.552632\n",
      "- Collect feature importance \n",
      "\n",
      "Decision Tree\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "        Algorithm              Metric  Metric value\n",
      "0   Decision Tree       AUC-ROC Train      0.687910\n",
      "1   Decision Tree         AUC-ROC Val      0.623897\n",
      "2   Decision Tree       AUC-PRC Train      0.679377\n",
      "3   Decision Tree         AUC-PRC Val      0.592086\n",
      "4   Decision Tree      Accuracy Train      0.664606\n",
      "5   Decision Tree        Accuracy Val      0.625000\n",
      "6   Decision Tree  Precision Train: 0      0.654564\n",
      "7   Decision Tree    Precision Val: 0      0.648148\n",
      "8   Decision Tree  Precision Train: 1      0.693939\n",
      "9   Decision Tree    Precision Val: 1      0.555556\n",
      "10  Decision Tree     Recall Train: 0      0.862022\n",
      "11  Decision Tree       Recall Val: 0      0.813953\n",
      "12  Decision Tree     Recall Train: 1      0.407473\n",
      "13  Decision Tree       Recall Val: 1      0.344828\n",
      "14  Decision Tree   F1-score Train: 0      0.744104\n",
      "15  Decision Tree     F1-score Val: 0      0.721649\n",
      "16  Decision Tree   F1-score Train: 1      0.513453\n",
      "17  Decision Tree     F1-score Val: 1      0.425532\n",
      "- Collect feature importance \n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo_1 = DataTranformTrain(label = 'label_1', drop_labels_list = ['label_1', 'label_X', 'label_2'])\n",
    "algo_best_model_1 = algo_1.grid_search(models=models, params=params, save_to_mlflow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_X\n",
      "- Importing train, test and val\n",
      "- Calculating significant features\n",
      "- Hyperparameter-tuning and training best model for each algo: \n",
      "\n",
      "Logistic Regression\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "Decision Tree\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "Random Forest\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "Gradient Boosting\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "XGBoost\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.522937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.499415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.494477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.480182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.458609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name   AUC_ROC\n",
       "0        Random Forest  0.522937\n",
       "1    Gradient Boosting  0.499415\n",
       "2  Logistic Regression  0.494477\n",
       "3              XGBoost  0.480182\n",
       "4        Decision Tree  0.458609"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_X = DataTranformTrain(label = 'label_X', drop_labels_list = ['label_1', 'label_X', 'label_2'])\n",
    "algo_best_model_X = algo_X.grid_search(models=models, params=params, save_to_mlflow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_2\n",
      "- Importing train, test and val\n",
      "- Calculating significant features\n",
      "- Hyperparameter-tuning and training best model for each algo: \n",
      "\n",
      "Logistic Regression\n",
      "- Hyperparameter-tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcus Bergdahl\\data_science_projects\\FPL_predictions\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Select best hyperparameters\n",
      "- Train best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcus Bergdahl\\data_science_projects\\FPL_predictions\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Calculating metrics \n",
      "\n",
      "Decision Tree\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "Random Forest\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "Gradient Boosting\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n",
      "XGBoost\n",
      "- Hyperparameter-tuning\n",
      "- Select best hyperparameters\n",
      "- Train best model\n",
      "- Calculating metrics \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.729437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.709235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.695527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.657828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.655213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name   AUC_ROC\n",
       "0        Random Forest  0.729437\n",
       "1  Logistic Regression  0.709235\n",
       "2    Gradient Boosting  0.695527\n",
       "3        Decision Tree  0.657828\n",
       "4              XGBoost  0.655213"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_2 = DataTranformTrain(label = 'label_2', drop_labels_list = ['label_1', 'label_X', 'label_2'])\n",
    "algo_best_model_2 = algo_2.grid_search(models=models, params=params, save_to_mlflow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo_best_model_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscore\u001b[39;00m \u001b[39mimport\u001b[39;00m extract_best_model, predict_result\n\u001b[1;32m----> 3\u001b[0m best_model_1 \u001b[39m=\u001b[39m extract_best_model(algo_best_model_1, algo_best_model_metric_1)\n\u001b[0;32m      4\u001b[0m best_model_X \u001b[39m=\u001b[39m extract_best_model(algo_best_model_X, algo_best_model_metric_X)\n\u001b[0;32m      5\u001b[0m best_model_2 \u001b[39m=\u001b[39m extract_best_model(algo_best_model_2, algo_best_model_metric_2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'algo_best_model_1' is not defined"
     ]
    }
   ],
   "source": [
    "from src.components.ml.score import extract_best_model, predict_result\n",
    "\n",
    "best_model_1 = extract_best_model(algo_best_model_1, algo_best_model_metric_1)\n",
    "best_model_X = extract_best_model(algo_best_model_X, algo_best_model_metric_X)\n",
    "best_model_2 = extract_best_model(algo_best_model_2, algo_best_model_metric_2)\n",
    "\n",
    "predictions = predict_result(best_model_1, best_model_X, best_model_2)\n",
    "predictions.to_csv('artifacts/result_predictions.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
